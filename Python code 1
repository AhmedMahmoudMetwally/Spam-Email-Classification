import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    confusion_matrix,
    classification_report
)

# -----------------------------
# Load the data
file_path = r"C:\Users\Pro\Downloads\email 1.csv"
data = pd.read_csv(file_path)

# -----------------------------
# Data preprocessing
data = data[['Category', 'Message']]  # Focus on the relevant columns
data.dropna(inplace=True)             # Drop any rows with NaN values

# Convert categories to numbers
data['Category'] = data['Category'].map({'ham': 0, 'spam': 1})
data.dropna(inplace=True)  # Drop again if there's any issue after conversion

X = data['Message']
y = data['Category']

# -----------------------------
# Split the data
X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1765, random_state=42, stratify=y_temp)

# -----------------------------
#  Convert text to numbers (TF-IDF)
vectorizer = TfidfVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_val_vec = vectorizer.transform(X_val)
X_test_vec = vectorizer.transform(X_test)

# -----------------------------
#  Build the model
model = MultinomialNB()
model.fit(X_train_vec, y_train)

# -----------------------------
#  Evaluate the model on the test set
y_pred = model.predict(X_test_vec)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# -----------------------------
# Print the results in a structured way
print("="*50)
print("ðŸ“§ Spam Email Classification Results")
print("="*50)
print(f"âœ… Accuracy : {accuracy:.4f}")
print(f"âœ… Precision: {precision:.4f}")
print(f"âœ… Recall   : {recall:.4f}")
print(f"âœ… F1-Score : {f1:.4f}")
print("="*50)

print("\nðŸ“‹ Classification Report:\n")
print(classification_report(y_test, y_pred, target_names=["Ham", "Spam"]))
print("="*50)

# -----------------------------
#  Print the confusion matrix (Table Format)
cm = confusion_matrix(y_test, y_pred)
print("\nðŸ”µ Confusion Matrix (Table Format):\n")
print(cm)
print("="*50)

# -----------------------------
#  Plot the confusion matrix
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])
plt.title('ðŸ“Š Confusion Matrix - Spam Email Classification')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# -----------------------------
#  Plot overall performance (Accuracy - Precision - Recall - F1)
metrics = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1}

plt.figure(figsize=(8,5))
sns.barplot(x=list(metrics.keys()), y=list(metrics.values()), palette='viridis')
plt.title('ðŸ“ˆ Performance Metrics')
plt.ylim(0,1)
for i, v in enumerate(metrics.values()):
    plt.text(i, v + 0.02, f"{v:.2f}", ha='center', fontweight='bold')
plt.show()
